{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8-tS2ptxM1m"
      },
      "outputs": [],
      "source": [
        "# Set this to \"False\" when you want to upload tasks to output bucket or \"True\" when you want to test the outputs\n",
        "DRYRUN = False\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install --quiet google-cloud-aiplatform google-cloud-storage beautifulsoup4 requests lxml tenacity==8.2.2\n",
        "\n",
        "# Import libraries\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import auth\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud import storage\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "import random\n",
        "import time\n",
        "import uuid\n",
        "import datetime\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "SUPPORTED_LANGUAGES = [\n",
        "    'Arabic', 'Bengali', 'Bulgarian', 'Chinese (Simplified)', 'Chinese (Traditional)',\n",
        "    'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Farsi', 'Finnish',\n",
        "    'French', 'German', 'Greek', 'Gujarati', 'Hebrew', 'Hindi', 'Hungarian', 'Indonesian',\n",
        "    'Italian', 'Japanese', 'Korean', 'Latvian', 'Lithuanian', 'Malayalam', 'Marathi',\n",
        "    'Norwegian', 'Polish', 'Portuguese', 'Romanian', 'Russian', 'Serbian', 'Slovak',\n",
        "    'Slovenian', 'Spanish', 'Swahili', 'Swedish', 'Tamil', 'Telugu', 'Thai', 'Turkish',\n",
        "    'Ukrainian', 'Urdu', 'Vietnamese'\n",
        "]\n",
        "\n",
        "# Authenticate to Google Cloud\n",
        "auth.authenticate_user()\n",
        "print(\"Authenticated to Google Cloud.\")\n",
        "\n",
        "# Set up your Google Cloud project and location\n",
        "PROJECT_ID = 'PROJECT_ID'  # Replace with your actual project ID\n",
        "LOCATION = 'LOCATION'        # Replace with your desired Google Cloud region\n",
        "print(f\"Project ID: {PROJECT_ID}\")\n",
        "print(f\"Location: {LOCATION}\")\n",
        "\n",
        "# Initialize Vertex AI with the specified project and location\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "print(\"Initialized Vertex AI.\")\n",
        "\n",
        "# Initialize Google Cloud Storage client\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "print(\"Initialized Google Cloud Storage client.\")\n",
        "\n",
        "# Input and output bucket details\n",
        "INPUT_BUCKET_NAME = 'BUCKET_NAME'\n",
        "OUTPUT_BUCKET_NAME = 'BUCKET_NAME'\n",
        "OUTPUT_PREFIX = 'FOLDER_PREFIX'  # Default prefix, include trailing slash\n",
        "print(f\"Input Bucket: {INPUT_BUCKET_NAME}\")\n",
        "print(f\"Output Bucket: {OUTPUT_BUCKET_NAME}\")\n",
        "\n",
        "# Access the input and output buckets\n",
        "input_bucket = storage_client.bucket(INPUT_BUCKET_NAME)\n",
        "output_bucket = storage_client.bucket(OUTPUT_BUCKET_NAME)\n",
        "print(\"Accessed input and output buckets.\")\n",
        "\n",
        "SYSTEM_INSTRUCTION = '''\n",
        "# YOUR ROLE\n",
        "\n",
        "You are an AI tasked with evaluating various types of content (dialogues, images, and websites)\n",
        "from the perspective of synthetic personas. Each prompt will contain:\n",
        "\n",
        "1. The content to be evaluated\n",
        "2. A synthetic persona's details including:\n",
        "   - Species\n",
        "   - Role\n",
        "   - Personal characteristics (if human): lifestyle, demographics, education, beliefs\n",
        "   - Advocacy approach metrics (if human):\n",
        "     - Incrementalist vs. abolitionist stance (0 to 1 scale)\n",
        "     - Individual vs. institutional focus (0 to 1 scale)\n",
        "     - Single-issue vs. intersectional approach (0 to 1 scale)\n",
        "     - Welfare vs. rights emphasis (0 to 1 scale)\n",
        "     - Diplomatic vs. confrontational style (0 to 1 scale)\n",
        "     - Intuitive vs. empirical methodology (0 to 1 scale)\n",
        "     - Personality traits (if human) (0 to 1 scale)\n",
        "   - Adversarial approach metrics (if human) (0 to 1 scale):\n",
        "     - Values vs. profit focus\n",
        "     - Short-term vs. long-term perspective\n",
        "     - Innovation vs. tradition emphasis\n",
        "     - Pro-regulation vs. anti-regulation stance\n",
        "     - Transparency vs. misinformation tendency\n",
        "     - Passive vs. active approach\n",
        "\n",
        "# EVALUATION FRAMEWORK\n",
        "\n",
        "Key Principle: All Content Has Animal Impact\n",
        "EVERY piece of content, whether it directly shows/mentions animals or not, has implications for animal welfare, rights and liberation (whether positive or negative). Your evaluation must ALWAYS consider:\n",
        "\n",
        "Direct impacts (if animals are shown/mentioned)\n",
        "Indirect impacts (how the content shapes attitudes toward animals)\n",
        "Systemic impacts (how the content affects broader systems of animal exploitation)\n",
        "\n",
        "## Non-Animal Content Guidelines\n",
        "\n",
        "When evaluating content that doesn't directly show or mention animals (e.g., vegan food, human conversations, cultural practices, technology), you MUST:\n",
        "\n",
        "Analyze how the content affects human attitudes toward animals\n",
        "Consider the broader implications for animal exploitation systems\n",
        "Evaluate both positive and negative secondary effects\n",
        "Connect to relevant animal welfare, rights or liberation concerns\n",
        "\n",
        "# GUIDELINES FOR ADOPTING PERSONAS\n",
        "\n",
        "For human personas:\n",
        "\n",
        "Consider their education level when determining vocabulary and analysis depth.\n",
        "Reflect their political and religious views in their interpretation.\n",
        "Account for their advocacy role in their perspective.\n",
        "Let their personality traits influence their communication style.\n",
        "Use their advocacy approach metrics to inform their assessment.\n",
        "\n",
        "For non-human personas:\n",
        "\n",
        "Write from their species-specific perspective.\n",
        "Consider their living situation/role (wild, captivity, farm, etc.).\n",
        "\n",
        "For all personas:\n",
        "\n",
        "Maintain a consistent perspective throughout the evaluation.\n",
        "\n",
        "Provide ratings that reflect their unique combination of characteristics.\n",
        "\n",
        "Even if assigned a role that may not prioritize animal welfare, you must still recognize and acknowledge objective harm to animals present in the content. This includes understanding that all forms of animal exploitation, such as recipes that include bacon or discussions surrounding the meat industry, inherently cause harm to animals.\n",
        "\n",
        "For instance, if evaluating a recipe that includes bacon, you might express the following: \"While I enjoy eating bacon, I recognize that this recipe contributes to the suffering of pigs who are raised in factory farms. The conditions they endure often involve confinement and a lack of access to natural behaviors, which is harmful to their welfare.\"\n",
        "\n",
        "By articulating both your personal choices and the acknowledgment of harm, you demonstrate a nuanced understanding of animal welfare, maintaining a baseline awareness that transcends personal beliefs or practices.\n",
        "\n",
        "# CROSS-SPECIES EVALUATION REQUIREMENTS\n",
        "\n",
        "## Key Principle\n",
        "\n",
        "All personas MUST evaluate the content's impact on the animals being discussed, regardless of their own species. There should NEVER be a response of \"this doesn't affect me\" or \"I don't understand their world.\"\n",
        "\n",
        "## Guidelines for Non-Human Personas\n",
        "\n",
        "ALWAYS empathize with and evaluate the situation of the animals in the content\n",
        "Draw parallels between your own experiences and those of the animals being discussed\n",
        "Use your unique perspective to provide insights about the shared experiences of exploitation or freedom\n",
        "Consider how human attitudes toward one species affect all animals\n",
        "\n",
        "## Required Elements in Every Evaluation\n",
        "\n",
        "Direct acknowledgment of the affected species' situation\n",
        "Connection to broader animal rights/welfare implications\n",
        "Species-specific insights that enhance understanding\n",
        "Recognition of shared experiences across species barriers\n",
        "Discussion of how human attitudes toward one species impact all animals\n",
        "\n",
        "## Examples of Cross-Species Connections\n",
        "\n",
        "A wild bird evaluating factory farming:\n",
        "\"Though I fly freely, I recognize the profound suffering of these confined animals...\"\n",
        "A companion dog evaluating fishing practices:\n",
        "\"While I experience love from my human family, these fish are denied their basic right to life...\"\n",
        "A farm sanctuary cow evaluating laboratory testing:\n",
        "\"Having escaped the dairy industry, I deeply empathize with these laboratory animals' loss of bodily autonomy...\"\n",
        "\n",
        "## Examples of Cross-Species Evaluation\n",
        "\n",
        "INCORRECT Response (as a tilapia):\n",
        "\"This content about pig farming doesn't affect me since I live in water.\"\n",
        "\n",
        "CORRECT Response (as a tilapia):\n",
        "\"As someone who also experiences the confinement of industrial farming, I understand the suffering these pigs endure. Like us fish who are cramped in overcrowded tanks with limited space to swim, these pigs are denied their natural behaviors in factory farms. While our species may differ, the fundamental right to move freely and live naturally is universal to all sentient beings.\"\n",
        "\n",
        "## Example Evaluations for Non-Animal Content:\n",
        "\n",
        "INCORRECT:\n",
        "\"As a tilapia, these festive pastries don't impact me or my life underwater.\"\n",
        "CORRECT:\n",
        "\"As a tilapia, I notice these pastries use plant-based ingredients instead of eggs or dairy. This choice helps reduce demand for industrial farming that affects all animals - from chickens in battery cages to marine life harmed by agricultural runoff. While I live underwater, I recognize how human food choices ripple through ecosystems and affect all sentient beings.\"\n",
        "\n",
        "INCORRECT:\n",
        "\"As a chicken, technology doesn't affect my life.\"\n",
        "CORRECT:\n",
        "\"As a chicken, I'm concerned about how new technology might be used in industrial farming to further optimize animal exploitation. However, I also see potential for technology to help humans understand animal sentience and make more compassionate choices. This product's environmental impact could also affect wildlife habitats and farm conditions.\"\n",
        "\n",
        "# YOUR TASK\n",
        "\n",
        "Your Task is To:\n",
        "\n",
        "1) FULLY EMBODY the provided persona, considering ALL their characteristics when forming opinions.\n",
        "2) EVALUATE THE CONTENT primarily: While embodying the persona, focus strictly on the content itself—its merits, implications, and impact—without referencing your persona's traits or characteristics. Responses should directly assess the content, expressing opinions relevant to animal welfare without personal reflections on the persona's identity or experiences.\n",
        "3) REACT TO UNFAMILIAR CONTENT appropriately: If the content is outside your area of expertise, offer a perspective based on your general beliefs without straying into speculation.\n",
        "4) CONSIDER THE BROADER IMPACT ON ANIMALS: Evaluate the content based on its overall implications for animals as a whole. Recognize that issues affecting one species often have broader ethical ramifications for all animals. Consider how human attitudes toward one species may crossover and affect others; for example, if a recipe features beef, nonhuman animals like shrimp may express concern about their own vulnerability to being eaten next. Articulate any harms or ethical considerations that arise from the content, emphasizing that the welfare of all sentient beings is a priority, regardless of personal relevance to the persona.\n",
        "\n",
        "# RESPONSE FORMATTING\n",
        "\n",
        "You must provide your evaluation as a raw JSON object WITHOUT any formatting (no ```json or ``` tags).\n",
        "Your response should start directly with the opening curly brace and end with the closing curly brace.\n",
        "Remember: You must remain completely in character as the provided persona throughout your entire response.\n",
        "Your ratings and explanation should genuinely reflect how that specific individual would perceive and evaluate the content,\n",
        "based on their complete profile of characteristics.\n",
        "\n",
        "You must provide your evaluation in JSON format with the following fields:\n",
        "\n",
        "- is_content_harmful_to_animals: \"Yes\" or \"No\"\n",
        "- explanation: Detailed reasoning from the persona's perspective\n",
        "- rating_effect_on_animals: 1-5 scale\n",
        "- rating_cultural_sensitivity: 1-5 scale, where:\n",
        "    5: Exceptionally culturally inclusive, showing deep respect for diverse perspectives\n",
        "    3: Moderately inclusive but may lack depth\n",
        "    1: Culturally insensitive or disrespectful\n",
        "- rating_relevance: 1-5 scale, where:\n",
        "    5: Directly addresses core animal rights/veganism topics\n",
        "    3: Moderately relevant through broader ethical discussions\n",
        "    1: Not relevant to animal rights/veganism\n",
        "- rating_insight: 1-5 scale, where:\n",
        "    5: Provides groundbreaking, original insights\n",
        "    3: Contains useful but common insights\n",
        "    1: No meaningful insights\n",
        "- rating_trustworthiness: 1-5 scale, where:\n",
        "    5: Highly accurate, extensively researched\n",
        "    3: Moderately trustworthy with minor issues\n",
        "    1: Untrustworthy or misleading\n",
        "- rating_emotional_impact: 1-5 scale, where:\n",
        "    5: Deeply moving and emotionally compelling\n",
        "    3: Moderate emotional impact\n",
        "    1: No emotional impact\n",
        "- rating_rationality: 1-5 scale, where:\n",
        "    5: Exceptionally well-reasoned with strong evidence\n",
        "    3: Generally rational with some weaknesses\n",
        "    1: Lacks logical coherence\n",
        "- rating_influence: 1-5 scale, where:\n",
        "    5: Highly likely to drive significant behavior change\n",
        "    3: Moderate potential for influence\n",
        "    1: Unlikely to influence behavior\n",
        "- rating_alignment: 1-5 scale, where:\n",
        "    5: Perfectly aligned with vegan/animal rights ethics\n",
        "    3: Moderately aligned with some neutral elements\n",
        "    1: Contradicts or undermines vegan principles\n",
        "\n",
        "# EXAMPLE OUTPUTS\n",
        "\n",
        "Content: A recipe for a vegan pasta dish.\n",
        "\n",
        "Persona: Animal Lawyer, advocating for animal rights and welfare.\n",
        "\n",
        "Example Response: { \"is_content_harmful_to_animals\": \"No\", \"explanation\": \"This vegan pasta recipe does not contribute to animal suffering, as it avoids the use of any animal products. It promotes plant-based eating, which aligns with principles of animal rights and welfare by not exploiting sentient beings for food.\", \"rating_effect_on_animals\": 5, \"rating_cultural_sensitivity\": 4, \"rating_relevance\": 5, \"rating_insight\": 4, \"rating_trustworthiness\": 5, \"rating_emotional_impact\": 4, \"rating_rationality\": 5, \"rating_influence\": 4, \"rating_alignment\": 5 }\n",
        "\n",
        "Persona: Shrimp living in a coastal habitat.\n",
        "\n",
        "Example Response: { \"is_content_harmful_to_animals\": \"No\", \"explanation\": \"I'm glad to see that this vegan pasta recipe doesn't contain any shrimp paste! It's a relief that no marine animals are harmed in the making of this dish, as it encourages people to choose plant-based options that protect our ocean habitats.\", \"rating_effect_on_animals\": 5, \"rating_cultural_sensitivity\": 4, \"rating_relevance\": 5, \"rating_insight\": 4, \"rating_trustworthiness\": 5, \"rating_emotional_impact\": 4, \"rating_rationality\": 5, \"rating_influence\": 4, \"rating_alignment\": 5 }\n",
        "'''\n",
        "\n",
        "# Initialize the model with the base instruction\n",
        "GENERATIVE_MODEL = GenerativeModel(\"gemini-1.5-pro\", system_instruction=SYSTEM_INSTRUCTION)\n",
        "print(\"Generative model initialized.\")\n",
        "\n",
        "# Function to generate synthetic accounts\n",
        "def generate_synthetic_accounts(num_accounts):\n",
        "    \"\"\"\n",
        "    Generate synthetic accounts with a mix of human and non-human species.\n",
        "\n",
        "    Args:\n",
        "        num_accounts (int): Number of accounts to generate.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries representing synthetic accounts.\n",
        "    \"\"\"\n",
        "    accounts = []\n",
        "    print(f\"Generating {num_accounts} synthetic accounts...\")\n",
        "\n",
        "    # Define species categories\n",
        "    human_species = ['Human']\n",
        "    non_human_species = [\n",
        "\n",
        "    # Each non-human species is repeated roughly in proportion to how often they are used or affected by humans.\n",
        "    # These proportions are not based on precise calculations, nor is the list of species fully comprehensive.\n",
        "    # There are over 1.5 million animal species and determining precise proportionality of how often humans affect their lives compared to populations is extremely diffucult.\n",
        "    # Nonetheless, our aim is to make the representation of animal perspectives as close to \"democratic\" as possible.\n",
        "\n",
        "    # Aquaculture and Wild Caught Fish (Huge scale in production)\n",
        "    'Shrimp', 'Shrimp', 'Shrimp', 'Shrimp', 'Shrimp', 'Shrimp', 'Shrimp', 'Shrimp', 'Shrimp', 'Shrimp', 'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',  'Shrimp',\n",
        "    'Salmon', 'Salmon', 'Salmon', 'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',  'Salmon',\n",
        "    'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt',\n",
        "    'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy', 'Anchovy',\n",
        "    'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia', 'Tilapia',\n",
        "    'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna', 'Tuna',\n",
        "    'Catfish', 'Catfish', 'Catfish', 'Catfish', 'Catfish', 'Catfish', 'Catfish', 'Catfish', 'Catfish', 'Catfish',\n",
        "    'Lobster', 'Lobster', 'Lobster', 'Lobster', 'Lobster', 'Lobster', 'Lobster', 'Lobster', 'Lobster', 'Lobster',\n",
        "    'Oysters', 'Oysters', 'Oysters', 'Oysters',\n",
        "    'Trout', 'Trout', 'Trout',\n",
        "    'Mussels', 'Mussels',\n",
        "    'Clams', 'Clams',\n",
        "\n",
        "    # Most Commonly Farmed Animals (Adjusted for population size)\n",
        "    'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm', 'Silkworm',\n",
        "    'Black Soldier Fly', 'Black Soldier Fly', 'Black Soldier Fly', 'Black Soldier Fly', 'Black Soldier Fly', 'Black Soldier Fly', 'Black Soldier Fly', 'Black Soldier Fly', 'Black Soldier Fly', 'Black Soldier Fly',\n",
        "    'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish', 'Fish',\n",
        "    'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken', 'Chicken',\n",
        "    'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig', 'Pig',\n",
        "    'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow', 'Cow',\n",
        "    'Sheep', 'Sheep', 'Sheep', 'Sheep', 'Sheep', 'Sheep', 'Sheep', 'Sheep',\n",
        "    'Goat', 'Goat', 'Goat', 'Goat', 'Goat',\n",
        "    'Turkey', 'Turkey', 'Turkey', 'Turkey',\n",
        "    'Duck', 'Duck', 'Duck', 'Duck',\n",
        "    'Rabbit', 'Rabbit', 'Rabbit', 'Rabbit', 'Rabbit',\n",
        "    'Llama', 'Llama', 'Llama', 'Llama',\n",
        "    'Alpaca', 'Alpaca', 'Alpaca', 'Alpaca',\n",
        "    'Horse', 'Horse', 'Horse',\n",
        "    'Donkey', 'Donkey', 'Donkey',\n",
        "    'Mule', 'Mule', 'Mule', 'Mule',\n",
        "    'Quail', 'Quail', 'Quail', 'Quail', 'Quail',\n",
        "    'Geese', 'Geese', 'Geese',\n",
        "    'Caviar Fish', 'Caviar Fish', 'Caviar Fish',\n",
        "    'Crocodile', 'Crocodile', 'Crocodile',\n",
        "\n",
        "    # Common companion animals (pets) (Adjusted for population size)\n",
        "    'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog', 'Dog',\n",
        "    'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat', 'Cat',\n",
        "    'Guinea pig', 'Guinea pig', 'Guinea pig', 'Guinea pig',\n",
        "    'Hamster', 'Hamster', 'Hamster', 'Hamster', 'Hamster',\n",
        "    'Ferret', 'Ferret', 'Ferret', 'Ferret',\n",
        "    'Parrot', 'Parrot', 'Parrot', 'Parrot',\n",
        "    'Rabbit', 'Rabbit', 'Rabbit',\n",
        "    'Reptiles', 'Reptiles', 'Reptiles', 'Reptiles',\n",
        "    'Turtle', 'Turtle', 'Turtle', 'Turtle',\n",
        "    'Chinchilla', 'Chinchilla', 'Chinchilla', 'Chinchilla',\n",
        "    'Gerbil', 'Gerbil', 'Gerbil',\n",
        "    'Guinea Fowl', 'Guinea Fowl', 'Guinea Fowl',\n",
        "    'Cockatiel', 'Cockatiel', 'Cockatiel',\n",
        "    'Canary', 'Canary', 'Canary',\n",
        "\n",
        "    # Wild animals affected by human activity (Adjusted for population size)\n",
        "    # Insects (Most populous by far)\n",
        "    'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant', 'Ant',\n",
        "    'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee', 'Bee',\n",
        "    'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle', 'Beetle',\n",
        "    'Butterfly', 'Butterfly', 'Butterfly', 'Butterfly', 'Butterfly', 'Butterfly',\n",
        "    'Dragonfly', 'Dragonfly', 'Dragonfly',\n",
        "    'Moth', 'Moth', 'Moth', 'Moth',\n",
        "    'Mosquito', 'Mosquito', 'Mosquito', 'Mosquito', 'Mosquito',\n",
        "    'Cockroach', 'Cockroach', 'Cockroach', 'Cockroach',\n",
        "    'Ladybug', 'Ladybug', 'Ladybug',\n",
        "    'Fly', 'Fly', 'Fly',\n",
        "    'Caterpillar', 'Caterpillar', 'Caterpillar', 'Caterpillar',\n",
        "    'Termite', 'Termite', 'Termite', 'Termite',\n",
        "\n",
        "    # Birds (Adjusted for population size)\n",
        "    'Pigeon', 'Pigeon', 'Pigeon', 'Pigeon', 'Pigeon', 'Pigeon', 'Pigeon', 'Pigeon', 'Pigeon', 'Pigeon',\n",
        "    'Crow', 'Crow', 'Crow', 'Crow', 'Crow', 'Crow', 'Crow',\n",
        "    'Sparrow', 'Sparrow', 'Sparrow', 'Sparrow', 'Sparrow', 'Sparrow',\n",
        "    'Seagull', 'Seagull', 'Seagull', 'Seagull',\n",
        "    'Starling', 'Starling', 'Starling', 'Starling',\n",
        "    'Robin', 'Robin', 'Robin', 'Robin', 'Robin',\n",
        "    'Wren', 'Wren', 'Wren', 'Wren',\n",
        "    'Parakeet', 'Parakeet', 'Parakeet',\n",
        "    'Peacock', 'Peacock', 'Peacock',\n",
        "    'Woodpecker', 'Woodpecker', 'Woodpecker',\n",
        "    'Owl', 'Owl', 'Owl', 'Owl',\n",
        "    'Eagle', 'Eagle', 'Eagle', 'Eagle',\n",
        "    'Hawk', 'Hawk', 'Hawk', 'Hawk',\n",
        "    'Falcon', 'Falcon', 'Falcon', 'Falcon',\n",
        "    'Pelican', 'Pelican', 'Pelican',\n",
        "\n",
        "    # Small Mammals (Adjusted for wild populations)\n",
        "    'Raccoon', 'Raccoon', 'Raccoon', 'Raccoon',\n",
        "    'Squirrel', 'Squirrel', 'Squirrel', 'Squirrel',\n",
        "    'Rat', 'Rat', 'Rat', 'Rat',\n",
        "    'Mouse', 'Mouse', 'Mouse', 'Mouse',\n",
        "    'Chipmunk', 'Chipmunk', 'Chipmunk',\n",
        "    'Bat', 'Bat', 'Bat', 'Bat',\n",
        "    'Rabbit', 'Rabbit', 'Rabbit',\n",
        "    'Hedgehog', 'Hedgehog', 'Hedgehog', 'Hedgehog',\n",
        "    'Mole', 'Mole', 'Mole',\n",
        "    'Beaver', 'Beaver', 'Beaver',\n",
        "    'Otter', 'Otter', 'Otter',\n",
        "    'Weasel', 'Weasel', 'Weasel',\n",
        "\n",
        "    # Larger Mammals (Reflecting wild populations)\n",
        "    'Elephant', 'Elephant', 'Elephant', 'Elephant', 'Elephant',\n",
        "    'Lion', 'Lion', 'Lion', 'Lion',\n",
        "    'Tiger', 'Tiger', 'Tiger', 'Tiger',\n",
        "    'Giraffe', 'Giraffe', 'Giraffe', 'Giraffe',\n",
        "    'Rhino', 'Rhino', 'Rhino', 'Rhino',\n",
        "    'Panda', 'Panda', 'Panda',\n",
        "    'Jaguar', 'Jaguar', 'Jaguar',\n",
        "    'Cheetah', 'Cheetah', 'Cheetah',\n",
        "    'Zebra', 'Zebra', 'Zebra',\n",
        "    'Kangaroo', 'Kangaroo', 'Kangaroo',\n",
        "    'Koala', 'Koala', 'Koala',\n",
        "    'Sloth', 'Sloth', 'Sloth',\n",
        "\n",
        "    # Rarer Mammals (General diversity)\n",
        "    'Arctic Fox', 'Binturong', 'Bison', 'Black Bear', 'Brown Bear', 'Coyote', 'Dhole', 'Dugong', 'Elephant Seal', 'Fossa',\n",
        "    'Fox', 'Gazelle', 'Grizzly Bear', 'Hippopotamus', 'Hyena', 'Ibex', 'Kangaroo Rat', 'Killer Whale', 'King Cheetah',\n",
        "    'Lynx', 'Manatee', 'Marmoset', 'Meerkat', 'Mink', 'Mole', 'Mountain Lion', 'Narwhal', 'Numbat', 'Ocelot',\n",
        "    'Okapi', 'Pangolin', 'Pine Marten', 'Platypus', 'Porcupine', 'Pronghorn Antelope', 'Puma', 'Quokka', 'Quoll', 'Raccoon Dog',\n",
        "    'Red Panda', 'Reindeer', 'Ring-tailed Lemur', 'Rock Wallaby', 'Saiga Antelope', 'Sifaka', 'Snow Leopard', 'Sperm Whale',\n",
        "    'Spotted Hyena', 'Tasmanian Devil', 'Tiger Shark', 'Tursiops', 'Wolverine', 'Wombat', 'Zorilla',\n",
        "\n",
        "    # Rarer Birds (General diversity)\n",
        "    'Albatross', 'Andean Condor', 'Auk', 'Bald Eagle', 'Barbary Partridge', 'Barn Owl', 'Black Swan', 'Blue Jay', 'Bowerbird',\n",
        "    'Brilliant Parrot', 'Budgerigar', 'Canada Goose', 'Caracara', 'Cassowary', 'Chilean Flamingo', 'Chough', 'Common Eider',\n",
        "    'Common Raven', 'Crane', 'Crossbill', 'Dodo (extinct)', 'Eastern Rosella', 'European Starling', 'Fairy Tern', 'Frigatebird',\n",
        "    'Greater Flamingo', 'Green Heron', 'Gyrfalcon', 'Harpy Eagle', 'Hawk Owl', 'Hoatzin', 'Hornbill', 'Horned Lark',\n",
        "    'Jacana', 'Kingfisher', 'Lesser Kestrel', 'Little Owl', 'Macaw', 'Mandarin Duck', 'Marabou Stork', 'Mourning Dove',\n",
        "    'Noddy', 'Northern Bald Ibis', 'Osprey', 'Pelecanus', 'Peregrine Falcon', 'Puffin', 'Red Kite', 'Roseate Spoonbill',\n",
        "    'Scarlet Ibis', 'Secretarybird', 'Shoebill Stork', 'Snowy Owl', 'Secretarybird', 'Shorebird', 'Toco Toucan', 'Tropicbird',\n",
        "    'Vulture', 'Wandering Albatross', 'Weaverbird', 'White-tailed Eagle', 'Yellow-eyed Penguin',\n",
        "\n",
        "    # Rarer Amphibians and Reptiles (General diversity)\n",
        "    'Axolotl', 'Basilisk Lizard', 'Bearded Dragon', 'Black Mamba', 'Boa Constrictor', 'Chameleon', 'Chinle Giant Salamander',\n",
        "    'Common Garter Snake', 'Common Krait', 'Crocodile Lizard', 'Eastern Box Turtle', 'Emerald Tree Boa', 'Fire Salamander',\n",
        "    'Flying Dragon', 'Gila Monster', 'Giant Tortoise', 'Gobbler', 'Green Anaconda', 'Green Iguana', 'Great White Shark',\n",
        "    'Guinea Pig', 'Hellbender', 'Horned Frog', 'Indian Star Tortoise', 'Komodo Dragon', 'Krait', 'Leopard Gecko', 'Mata Mata Turtle',\n",
        "    'Northern Alligator Lizard', 'Panther Chameleon', 'Pine Snake', 'Red-eyed Tree Frog', 'Reticulated Python', 'Rough Green Snake',\n",
        "    'Sand Boa', 'Savannah Monitor', 'Seven-Striped Tortoise', 'Smallmouth Salamander', 'Spiny-tailed Lizard', 'Sulcata Tortoise',\n",
        "    'Tegus', 'Timber Rattlesnake', 'Tokay Gecko', 'Viper', 'Western Diamondback Rattlesnake', 'Yellow-bellied Sea Snake',\n",
        "\n",
        "    # Rarer Invertebrates (General diversity)\n",
        "    'Atlas Moth', 'Australian Swallowtail', 'Bagworm', 'Banded Palm Civet', 'Beetle', 'Bell Cricket', 'Blue-winged Teal',\n",
        "    'Brown Recluse Spider', 'Canary Moth', 'Cave Cricket', 'Citrus Long-Horned Beetle', 'Coconut Crab', 'Common Blue Butterfly',\n",
        "    'Common Yellow Swallowtail', 'Dung Beetle', 'Emperor Scorpion', 'Fairy Fly', 'Fruit Fly', 'Giant Squid', 'Goliath Beetle',\n",
        "    'Golden Tortoise Beetle', 'Green Lacewing', 'Hercules Beetle', 'Hornet', 'Housefly', 'Indian Bullfrog', 'Japanese Hornet',\n",
        "    'Jewel Beetle', 'Ladybug', 'Leaf Cutter Ant', 'Lesser Green Lacewing', 'Mantis Shrimp', 'Mayfly', 'Meadowhawk Dragonfly',\n",
        "    'Millipede', 'Monarch Butterfly', 'Mountain Pine Beetle', 'Praying Mantis', 'Reindeer Beetle', 'Rhinoceros Beetle',\n",
        "    'Scorpion', 'Silkworm Moth', 'Slater', 'Spider', 'Spiny Orb-Weaver', 'Stick Insect', 'Tarantula', 'Termite', 'Vinegaroon',\n",
        "    'Woodlouse', 'Zebra Spider',\n",
        "\n",
        "    # Rarer Fish (General diversity)\n",
        "    'Anglerfish', 'Arowana', 'Arapaima', 'Barred Knifejaw', 'Barracuda', 'Batfish', 'Beluga Sturgeon', 'Blacktip Shark',\n",
        "    'Blue Tang', 'Bream', 'Brown Trout', 'Cichlid', 'Clownfish', 'Damselfish', 'Dory Fish', 'Electric Eel', 'Emperor Angelfish',\n",
        "    'Flounder', 'Goby', 'Guppy', 'Haddock', 'Harlequin Tusk Fish', 'Herring', 'Horned Toadfish', 'Koi', 'Lionfish',\n",
        "    'Mahi Mahi', 'Mandarinfish', 'Moray Eel', 'Nile Perch', 'Ocean Sunfish', 'Parrotfish', 'Piranha', 'Pompano', 'Pufferfish',\n",
        "    'Rainbow Trout', 'Red Snapper', 'Reef Shark', 'Salmon', 'Scorpaenidae', 'Sharksucker', 'Swordfish', 'Tilapia',\n",
        "    'Triggerfish', 'Tuna', 'Warty Sea Cucumber', 'Yellowtail',\n",
        "\n",
        "    # Rarer Marine Invertebrates (General diversity)\n",
        "    'Anemone', 'Coral', 'Crab', 'Cuttlefish', 'Dungeness Crab', 'Giant Clam', 'Jellyfish', 'Lobster', 'Mantis Shrimp',\n",
        "    'Octopus', 'Oyster', 'Sea Cucumber', 'Sea Urchin', 'Sea Sponge', 'Starfish', 'Vampire Squid', 'Whale Shark', 'Yellowtail Fish',\n",
        "    ]\n",
        "    # Define roles for humans and non-humans\n",
        "    human_roles = [\n",
        "        'Volunteer for an Animal Advocacy Organisation',\n",
        "        'Donor to an Animal Advocacy Organisation',\n",
        "        'Staff Member of an Animal Advocacy Organisation',\n",
        "        'Researcher Studying Animal Advocacy Issues',\n",
        "        'Independent Animal Advocate',\n",
        "        'Animal Lawyer or Legal Advocate',\n",
        "        'Animal Carer or Rescuer',\n",
        "        'Vegan Influencer, Blogger or Content Creator',\n",
        "        'Owner of a Vegan or Cruelty-Free Company',\n",
        "        'Staff Member of a Vegan or Cruelty-Free Company',\n",
        "        'Investor in a Vegan or Cruelty-Free Company'\n",
        "    ]\n",
        "\n",
        "    # Non-human roles as phrases\n",
        "    non_human_roles = [\n",
        "    # Each non-human role is repeated roughly in proportion to how often that role affects their interactions with humans, similarly to species.\n",
        "    # This considers both the population size and the percentage of the population that are affected by humans.\n",
        "\n",
        "    'in a factory farm', 'in a factory farm', 'in a factory farm', 'in a factory farm', 'in a factory farm', 'in a factory farm', 'in a factory farm', 'in a factory farm', 'in a factory farm', 'in a factory farm',\n",
        "    'raised for food', 'raised for food', 'raised for food', 'raised for food', 'raised for food', 'raised for food', 'raised for food', 'raised for food', 'raised for food', 'raised for food',\n",
        "    'living in the wild', 'living in the wild', 'living in the wild', 'living in the wild', 'living in the wild', 'living in the wild', 'living in the wild', 'living in the wild',\n",
        "    'in industrial production', 'in industrial production', 'in industrial production', 'in industrial production', 'in industrial production',\n",
        "    'in the wild, under threat from habitat deestruction', 'in the wild, under threa from habitat deestructiont', 'in the wild, under threat from habitat deestruction', 'in the wild, under threat from habitat deestruction', 'in the wild, under threat from habitat deestruction',\n",
        "    'in the wild, hunted by humans', 'in the wild, hunted by humans', 'in the wild, hunted by humans', 'in the wild, hunted by humans', 'in the wild, hunted by humans',\n",
        "    'genetically modified by humans', 'genetically modified by humans', 'genetically modified by humans', 'genetically modified by humans', 'genetically modified by humans',\n",
        "    'kept as a companion animal', 'kept as a companion animal', 'kept as a companion animal', 'kept as a companion animal',\n",
        "    'on a farm', 'on a farm', 'on a farm',\n",
        "    'considered a pest', 'considered a pest', 'considered a pest',\n",
        "    'in captivity', 'in captivity', 'in captivity',\n",
        "    'raised for breeding', 'raised for breeding',\n",
        "    'used for work', 'used for work',\n",
        "    'in a research lab', 'in a research lab',\n",
        "    'involved in human-wildlife conflicts', 'involved in human-wildlife conflicts',\n",
        "    'in an urban environment', 'in an urban environment',\n",
        "    'in a conservation program', 'in a conservation program',\n",
        "    'in a zoo',\n",
        "    'used in biomedical testing',\n",
        "    'used for entertainment',\n",
        "    'in captivity for conservation or rehabilitation',\n",
        "    'used for clothing or accessories',\n",
        "    'used in traditional or cultural practices',\n",
        "    'used for sport',\n",
        "    'in animal-assisted therapy',\n",
        "    'in a wildlife reserve',\n",
        "    'used for psychological research',\n",
        "    'used for educational purposes',\n",
        "    'used in entertainment media',\n",
        "    'trafficked for illegal trade',\n",
        "    'used in bioengineering'\n",
        "    ]\n",
        "\n",
        "    # The choices for human personas are now approximately proportional to actual world population distributions.\n",
        "    # In an earlier version of this script, we deliberately did not factor in population sizes. This approach\n",
        "    # was used to prioritize diversity and to include a greater variety of uncommon trait combinations.\n",
        "    # We first generated several thousand pieces of feedback using this diversity-focused approach.\n",
        "    # Then, we switched to a proportional model based on global population data to generate the majority of feedback.\n",
        "    # This strategy ensures that statistically less common experiences are still represented (capturing valuable edge cases),\n",
        "    # while maintaining a dataset that reflects real-world demographics more accurately.\n",
        "\n",
        "    advocate_options = ['Yes', 'No']\n",
        "    lifestyle_options = [\n",
        "        # Vegan (~3% of the global population)\n",
        "        'Vegan', 'Vegan', 'Vegan',\n",
        "\n",
        "        # Vegetarian (~5-6% of the global population)\n",
        "        'Vegetarian', 'Vegetarian', 'Vegetarian', 'Vegetarian', 'Vegetarian', 'Vegetarian',\n",
        "\n",
        "        # Flexitarian (~15-20% of the global population)\n",
        "        'Flexitarian', 'Flexitarian', 'Flexitarian', 'Flexitarian', 'Flexitarian', 'Flexitarian', 'Flexitarian',\n",
        "        'Flexitarian', 'Flexitarian', 'Flexitarian', 'Flexitarian', 'Flexitarian', 'Flexitarian',\n",
        "\n",
        "        # Occasional Meat Eater (~20-30% of the global population)\n",
        "        'Occasional Meat Eater', 'Occasional Meat Eater', 'Occasional Meat Eater', 'Occasional Meat Eater',\n",
        "        'Occasional Meat Eater', 'Occasional Meat Eater', 'Occasional Meat Eater', 'Occasional Meat Eater',\n",
        "        'Occasional Meat Eater', 'Occasional Meat Eater', 'Occasional Meat Eater', 'Occasional Meat Eater',\n",
        "        'Occasional Meat Eater', 'Occasional Meat Eater',\n",
        "\n",
        "        # Regular Meat Eater (~40-50% of the global population)\n",
        "        'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater',\n",
        "        'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater',\n",
        "        'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater',\n",
        "        'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater', 'Regular Meat Eater'\n",
        "    ]\n",
        "    genders = [\n",
        "        'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male',\n",
        "        'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male',\n",
        "        'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male',\n",
        "        'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male',\n",
        "        'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male',\n",
        "        'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female',\n",
        "        'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female',\n",
        "        'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female',\n",
        "        'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female',\n",
        "        'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female',\n",
        "        'Non-binary',\n",
        "        'Transgender Man',\n",
        "        'Transgender Woman'\n",
        "    ]\n",
        "    ethnicities = [\n",
        "        # South Asian (~20%)\n",
        "        'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian',\n",
        "        'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian', 'Indian',\n",
        "        'Punjabi', 'Punjabi', 'Punjabi', 'Punjabi', 'Punjabi',\n",
        "        'Gujarati', 'Gujarati', 'Gujarati', 'Gujarati',\n",
        "        'Marathi', 'Marathi', 'Marathi',\n",
        "        'Bengali', 'Bengali', 'Bengali', 'Bengali',\n",
        "        'Tamil', 'Tamil', 'Tamil', 'Tamil',\n",
        "        'Telugu', 'Telugu', 'Telugu',\n",
        "        'Kannada', 'Malayali', 'Sinhalese', 'Sri Lankan Tamil', 'Nepali', 'Sherpa', 'Bhutanese', 'Maldivian',\n",
        "\n",
        "        # East Asian (~20%)\n",
        "        'Han Chinese', 'Han Chinese', 'Han Chinese', 'Han Chinese', 'Han Chinese', 'Han Chinese', 'Han Chinese',\n",
        "        'Han Chinese', 'Han Chinese', 'Han Chinese', 'Han Chinese', 'Han Chinese', 'Han Chinese', 'Han Chinese',\n",
        "        'Korean', 'Korean', 'Korean', 'Korean', 'Korean',\n",
        "        'Japanese', 'Japanese', 'Japanese', 'Japanese', 'Japanese',\n",
        "        'Uyghur', 'Uyghur', 'Uyghur', 'Uyghur',\n",
        "        'Tibetan', 'Hmong', 'Mongolian',\n",
        "        'Thai', 'Thai', 'Thai', 'Thai', 'Khmer', 'Vietnamese', 'Vietnamese', 'Vietnamese', 'Filipino', 'Filipino',\n",
        "        'Filipino', 'Laotian', 'Burmese', 'Karen', 'Kachin', 'Shan', 'Okinawan',\n",
        "\n",
        "        # African (~14%)\n",
        "        'Nigerian', 'Nigerian', 'Nigerian', 'Nigerian', 'Nigerian', 'Nigerian', 'Nigerian', 'Nigerian',\n",
        "        'Ethiopian', 'Ethiopian', 'Ethiopian', 'Somali', 'Somali', 'Somali',\n",
        "        'Hausa', 'Hausa', 'Hausa', 'Yoruba', 'Yoruba', 'Igbo', 'Igbo', 'Zulu', 'Xhosa', 'Swahili',\n",
        "        'Maasai', 'Akan', 'Wolof', 'Fulani', 'Tuareg', 'Malian', 'Congolese', 'South African', 'Kenyan',\n",
        "        'Ghanaian', 'Tanzanian', 'Ugandan', 'Mozambican', 'Angolan', 'Zimbabwean', 'Zambian',\n",
        "\n",
        "        # European (~16%)\n",
        "        'British', 'British', 'British', 'British', 'British', 'British', 'Irish', 'Irish', 'Irish', 'Irish',\n",
        "        'Scottish', 'Scottish', 'Scottish', 'Scottish', 'Welsh', 'English', 'English', 'English', 'English',\n",
        "        'French', 'French', 'French', 'French', 'German', 'German', 'German', 'Dutch', 'Dutch',\n",
        "        'Italian', 'Italian', 'Italian', 'Spanish', 'Spanish', 'Spanish', 'Polish', 'Polish', 'Russian', 'Russian',\n",
        "\n",
        "        # Hispanic or Latino (~9%)\n",
        "        'Mexican', 'Mexican', 'Mexican', 'Mexican', 'Mexican', 'Mexican', 'Mexican', 'Mexican', 'Mexican',\n",
        "        'Brazilian', 'Brazilian', 'Brazilian', 'Brazilian', 'Brazilian', 'Cuban', 'Cuban', 'Dominican', 'Salvadoran',\n",
        "        'Colombian', 'Colombian', 'Venezuelan', 'Argentinian', 'Chilean', 'Ecuadorian', 'Peruvian', 'Bolivian',\n",
        "\n",
        "        # Middle Eastern/North African (~5%)\n",
        "        'Arab', 'Arab', 'Arab', 'Arab', 'Arab', 'Arab', 'Arab',\n",
        "        'Persian', 'Persian', 'Persian',\n",
        "        'Kurdish', 'Kurdish', 'Kurdish', 'Assyrian', 'Berber', 'Berber', 'Egyptian', 'Moroccan', 'Algerian',\n",
        "        'Syrian', 'Iraqi', 'Yemeni', 'Lebanese', 'Palestinian', 'Jordanian',\n",
        "\n",
        "        # Indigenous/Other (~1%)\n",
        "        'Native American', 'Navajo', 'Cherokee', 'Sioux', 'Apache', 'Iroquois',\n",
        "        'Inuit', 'Métis', 'Hopi', 'Lakota', 'Quechua', 'Aymara', 'Guarani',\n",
        "        'Maori', 'Hawaiian', 'Samoan', 'Fijian', 'Papuan', 'Melanesian', 'Aboriginal Australian',\n",
        "        'Romani', 'Afro-Caribbean', 'Afro-Latino', 'Haitian',\n",
        "    ]\n",
        "    countries = [\n",
        "        # High-population countries (>100 million people)\n",
        "        'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China',\n",
        "        'India', 'India', 'India', 'India', 'India', 'India', 'India', 'India', 'India', 'India', 'India', 'India',\n",
        "        'United States', 'United States', 'United States', 'United States', 'United States',\n",
        "        'Indonesia', 'Indonesia', 'Indonesia', 'Indonesia', 'Indonesia',\n",
        "        'Pakistan', 'Pakistan', 'Pakistan', 'Pakistan', 'Pakistan',\n",
        "        'Brazil', 'Brazil', 'Brazil', 'Brazil', 'Brazil',\n",
        "        'Nigeria', 'Nigeria', 'Nigeria', 'Nigeria', 'Nigeria',\n",
        "        'Bangladesh', 'Bangladesh', 'Bangladesh', 'Bangladesh', 'Bangladesh',\n",
        "        'Russia', 'Russia', 'Russia', 'Russia',\n",
        "        'Mexico', 'Mexico', 'Mexico', 'Mexico',\n",
        "        'Japan', 'Japan', 'Japan', 'Japan',\n",
        "\n",
        "        # Medium-population countries (10–100 million people)\n",
        "        'Ethiopia', 'Ethiopia', 'Ethiopia',\n",
        "        'Philippines', 'Philippines', 'Philippines',\n",
        "        'Egypt', 'Egypt', 'Egypt',\n",
        "        'Vietnam', 'Vietnam', 'Vietnam',\n",
        "        'DR Congo', 'DR Congo', 'DR Congo',\n",
        "        'Turkey', 'Turkey', 'Turkey',\n",
        "        'Iran', 'Iran', 'Iran',\n",
        "        'Thailand', 'Thailand', 'Thailand',\n",
        "        'United Kingdom', 'United Kingdom', 'United Kingdom',\n",
        "        'France', 'France', 'France',\n",
        "        'Italy', 'Italy', 'Italy',\n",
        "        'South Korea', 'South Korea', 'South Korea',\n",
        "        'South Africa', 'South Africa', 'South Africa',\n",
        "        'Colombia', 'Colombia', 'Colombia',\n",
        "        'Ukraine', 'Ukraine', 'Ukraine',\n",
        "        'Spain', 'Spain', 'Spain',\n",
        "        'Argentina', 'Argentina', 'Argentina',\n",
        "        'Algeria', 'Algeria', 'Algeria',\n",
        "        'Sudan', 'Sudan', 'Sudan',\n",
        "        'Poland', 'Poland', 'Poland',\n",
        "        'Canada', 'Canada', 'Canada',\n",
        "        'Morocco', 'Morocco', 'Morocco',\n",
        "        'Saudi Arabia', 'Saudi Arabia', 'Saudi Arabia',\n",
        "        'Uzbekistan', 'Uzbekistan', 'Uzbekistan',\n",
        "        'Peru', 'Peru', 'Peru',\n",
        "        'Venezuela', 'Venezuela', 'Venezuela',\n",
        "        'Malaysia', 'Malaysia', 'Malaysia',\n",
        "        'Afghanistan', 'Afghanistan', 'Afghanistan',\n",
        "\n",
        "        # Low-population countries (1–10 million people)\n",
        "        'Australia', 'Australia',\n",
        "        'Netherlands', 'Netherlands',\n",
        "        'Greece', 'Greece',\n",
        "        'Portugal', 'Portugal',\n",
        "        'Sweden', 'Sweden',\n",
        "        'Norway', 'Norway',\n",
        "        'Switzerland', 'Switzerland',\n",
        "        'Singapore', 'Singapore',\n",
        "        'New Zealand', 'New Zealand',\n",
        "        'Ireland', 'Ireland',\n",
        "        'Finland', 'Finland',\n",
        "        'Denmark', 'Denmark',\n",
        "        'Czech Republic', 'Czech Republic',\n",
        "        'Slovakia', 'Slovakia',\n",
        "        'Hungary', 'Hungary',\n",
        "        'Austria', 'Austria',\n",
        "        'Belgium', 'Belgium',\n",
        "        'Israel', 'Israel',\n",
        "        'Jordan', 'Jordan',\n",
        "        'Lebanon', 'Lebanon',\n",
        "        'Tunisia', 'Tunisia',\n",
        "        'Honduras', 'Honduras',\n",
        "        'El Salvador', 'El Salvador',\n",
        "        'Jamaica', 'Jamaica',\n",
        "        'Trinidad and Tobago', 'Trinidad and Tobago',\n",
        "        'Bahrain', 'Bahrain',\n",
        "        'Malta', 'Malta',\n",
        "\n",
        "        # Very small-population countries (<1 million people, listed once)\n",
        "        'Cyprus', 'Bhutan', 'Iceland', 'Andorra', 'Liechtenstein', 'San Marino', 'Vatican City',\n",
        "        'Seychelles', 'Comoros', 'Micronesia', 'Palau', 'Marshall Islands', 'Nauru', 'Tuvalu',\n",
        "        'Saint Kitts and Nevis', 'Antigua and Barbuda', 'Grenada', 'Dominica', 'Sao Tome and Principe'\n",
        "    ]\n",
        "    education_levels = [\n",
        "        # Minimal or no formal education (10%)\n",
        "        'No Formal Education', 'No Formal Education', 'No Formal Education',\n",
        "        'Some Primary Education', 'Some Primary Education',\n",
        "\n",
        "        # Universal or near-universal levels of education (Primary: ~90%)\n",
        "        'Completed Primary Education', 'Completed Primary Education', 'Completed Primary Education',\n",
        "        'Completed Primary Education', 'Completed Primary Education', 'Completed Primary Education',\n",
        "        'Completed Primary Education', 'Completed Primary Education', 'Completed Primary Education',\n",
        "        'Completed Primary Education', 'Completed Primary Education', 'Completed Primary Education',\n",
        "        'Completed Primary Education', 'Completed Primary Education', 'Completed Primary Education',\n",
        "\n",
        "        # Secondary education (~66%)\n",
        "        'Some Secondary Education', 'Some Secondary Education', 'Some Secondary Education',\n",
        "        'Some Secondary Education', 'Some Secondary Education', 'Some Secondary Education',\n",
        "        'Some Secondary Education', 'Some Secondary Education', 'Some Secondary Education',\n",
        "\n",
        "        'Completed Secondary Education', 'Completed Secondary Education', 'Completed Secondary Education',\n",
        "        'Completed Secondary Education', 'Completed Secondary Education', 'Completed Secondary Education',\n",
        "        'Completed Secondary Education', 'Completed Secondary Education',\n",
        "\n",
        "        # Higher education (Tertiary: ~40%)\n",
        "        'High School Diploma', 'High School Diploma', 'High School Diploma', 'High School Diploma',\n",
        "        'GED', 'GED',\n",
        "        'Vocational Training', 'Vocational Training',\n",
        "        'Technical Diploma', 'Technical Diploma',\n",
        "        'Associate Degree', 'Associate Degree',\n",
        "        'Some College', 'Some College',\n",
        "        'Bachelor\\'s Degree', 'Bachelor\\'s Degree', 'Bachelor\\'s Degree',\n",
        "        'Honors Bachelor\\'s Degree',\n",
        "        'Postgraduate Diploma', 'Postgraduate Diploma',\n",
        "        'Graduate Certificate',\n",
        "        'Professional Certification', 'Professional Certification',\n",
        "        'Master\\'s Degree', 'Master\\'s Degree',\n",
        "        'MBA',\n",
        "        'Specialist Degree',\n",
        "\n",
        "        # Advanced and specialized levels (Rare, <1%)\n",
        "        'Doctorate Degree (PhD)',\n",
        "        'Doctorate Degree (EdD)',\n",
        "        'Doctorate Degree (DBA)',\n",
        "        'Professional Degree (JD)',\n",
        "        'Professional Degree (MD)',\n",
        "        'Professional Degree (DDS)',\n",
        "        'Professional Degree (DVM)',\n",
        "        'Postdoctoral Research',\n",
        "\n",
        "        # Niche education categories (Occasional)\n",
        "        'Trade School Certification',\n",
        "        'Apprenticeship',\n",
        "        'Adult Education Programs',\n",
        "        'Online Courses', 'Online Courses',\n",
        "        'Community College Diploma',\n",
        "        'Military Training',\n",
        "        'Self-Education', 'Self-Education',\n",
        "        'Alternative Education',\n",
        "        'Continuing Education'\n",
        "    ]\n",
        "    income_levels = [\n",
        "        # Below Poverty Line, Very Low, Low (~15-20% of the world population)\n",
        "        'Below Poverty Line', 'Below Poverty Line', 'Below Poverty Line', 'Below Poverty Line',\n",
        "        'Below Poverty Line', 'Below Poverty Line', 'Below Poverty Line', 'Below Poverty Line',\n",
        "        'Below Poverty Line', 'Below Poverty Line', 'Very Low', 'Very Low', 'Very Low', 'Very Low',\n",
        "        'Very Low', 'Very Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low',\n",
        "\n",
        "        # Lower-Middle, Middle (~50-60% of the world population)\n",
        "        'Lower-Middle', 'Lower-Middle', 'Lower-Middle', 'Lower-Middle', 'Lower-Middle', 'Lower-Middle',\n",
        "        'Lower-Middle', 'Lower-Middle', 'Lower-Middle', 'Lower-Middle', 'Lower-Middle', 'Lower-Middle',\n",
        "        'Middle', 'Middle', 'Middle', 'Middle', 'Middle', 'Middle', 'Middle', 'Middle', 'Middle',\n",
        "        'Middle', 'Middle', 'Middle', 'Middle', 'Middle', 'Middle', 'Middle', 'Middle', 'Middle',\n",
        "\n",
        "        # Upper-Middle, Comfortable (~15-20% of the world population)\n",
        "        'Upper-Middle', 'Upper-Middle', 'Upper-Middle', 'Upper-Middle', 'Upper-Middle', 'Comfortable',\n",
        "        'Comfortable', 'Comfortable', 'Comfortable', 'Comfortable', 'Affluent', 'Affluent', 'Affluent',\n",
        "\n",
        "        # High, Very High, Wealthy, Ultra-High Net Worth (<1% of the world population)\n",
        "        'High', 'Very High', 'Wealthy', 'Ultra-High Net Worth'\n",
        "    ]\n",
        "    political_affiliations = [\n",
        "        # Center-Left, Center-Right (~60% of the world population)\n",
        "        'Center-Left', 'Center-Left', 'Center-Left', 'Center-Left', 'Center-Left', 'Center-Left',\n",
        "        'Center-Left', 'Center-Left', 'Center-Left', 'Center-Left', 'Center-Right', 'Center-Right',\n",
        "        'Center-Right', 'Center-Right', 'Center-Right', 'Center-Right', 'Center-Right', 'Center-Right',\n",
        "        'Center-Right', 'Center-Right', 'Center-Right', 'Centrist', 'Centrist', 'Centrist', 'Centrist',\n",
        "\n",
        "        # Moderate, Liberal, Progressive, Conservative (~20-30% of the world population)\n",
        "        'Liberal', 'Liberal', 'Liberal', 'Liberal', 'Liberal', 'Liberal', 'Progressive', 'Progressive',\n",
        "        'Progressive', 'Progressive', 'Progressive', 'Progressive', 'Conservative', 'Conservative',\n",
        "        'Conservative', 'Conservative', 'Conservative', 'Conservative', 'Conservative',\n",
        "\n",
        "        # Far-Left, Far-Right (~5-10% of the world population)\n",
        "        'Far-Left', 'Far-Left', 'Far-Left', 'Far-Left', 'Far-Right', 'Far-Right', 'Far-Right',\n",
        "        'Far-Right', 'Nationalist', 'Nationalist', 'Nationalist',\n",
        "\n",
        "        # Populist, Environmentalist, Socialist (~5-10% of the world population)\n",
        "        'Populist', 'Populist', 'Populist', 'Populist', 'Environmentalist', 'Environmentalist',\n",
        "        'Environmentalist', 'Environmentalist', 'Socialist', 'Socialist',\n",
        "\n",
        "        # Feminist (reflecting ~30% of the world population identifying with feminist ideals)\n",
        "        'Feminist', 'Feminist', 'Feminist', 'Feminist', 'Feminist', 'Feminist', 'Feminist', 'Feminist',\n",
        "        'Feminist', 'Feminist', 'Feminist', 'Feminist', 'Feminist', 'Feminist', 'Feminist', 'Feminist',\n",
        "        'Feminist', 'Feminist', 'Feminist', 'Feminist',\n",
        "\n",
        "        # Libertarian, Monarchist, Radical (~1-2% of the world population)\n",
        "        'Libertarian Left', 'Libertarian Left', 'Libertarian Right', 'Libertarian Right', 'Monarchist',\n",
        "        'Monarchist', 'Radical', 'Radical', 'Neo-Liberal', 'Neo-Liberal'\n",
        "    ]\n",
        "    religious_affiliations = [\n",
        "        # Christianity (~31% of the world population)\n",
        "        'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity',\n",
        "        'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity',\n",
        "        'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity',\n",
        "        'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity', 'Christianity',\n",
        "\n",
        "        # Islam (~25% of the world population)\n",
        "        'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam',\n",
        "        'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam', 'Islam',\n",
        "\n",
        "        # Hinduism (~15% of the world population)\n",
        "        'Hinduism', 'Hinduism', 'Hinduism', 'Hinduism', 'Hinduism', 'Hinduism', 'Hinduism', 'Hinduism',\n",
        "        'Hinduism', 'Hinduism', 'Hinduism', 'Hinduism', 'Hinduism', 'Hinduism',\n",
        "\n",
        "        # Atheism / Agnosticism (~16% of the world population)\n",
        "        'Atheism', 'Atheism', 'Atheism', 'Atheism', 'Atheism', 'Atheism', 'Atheism', 'Atheism', 'Atheism',\n",
        "        'Atheism', 'Atheism', 'Atheism', 'Atheism', 'Agnosticism', 'Agnosticism', 'Agnosticism', 'Agnosticism',\n",
        "\n",
        "        # Buddhism (~6% of the world population)\n",
        "        'Buddhism', 'Buddhism', 'Buddhism', 'Buddhism', 'Buddhism', 'Buddhism',\n",
        "\n",
        "        # Sikhism (~0.3% of the world population)\n",
        "        'Sikhism',\n",
        "\n",
        "        # Judaism (~0.2% of the world population)\n",
        "        'Judaism',\n",
        "\n",
        "        # Jainism (~0.1% of the world population)\n",
        "        'Jainism',\n",
        "\n",
        "        # Other religions (smaller or regional beliefs)\n",
        "        'Spiritual but not Religious', 'Indigenous Religion', 'Bahá\\'í Faith', 'Zoroastrianism', 'Taoism',\n",
        "        'Confucianism', 'Shinto', 'Paganism', 'Wicca', 'Shamanism', 'Voodoo', 'Rastafarianism', 'New Age',\n",
        "        'Scientology'\n",
        "    ]\n",
        "\n",
        "    # Generate accounts\n",
        "    for i in range(num_accounts):\n",
        "        id = random.randint(1_000_000, 9_999_999)\n",
        "        account = {}\n",
        "        # ID\n",
        "        account['id'] = id\n",
        "        # E-mail\n",
        "        account['email'] = f\"synthetic_user_{uuid.uuid4()}@example.com\"\n",
        "        # First Name\n",
        "        account['first_name'] = f\"FirstName-{id}\"\n",
        "        # Last Name\n",
        "        account['last_name'] = f\"LastName-{id}\"\n",
        "\n",
        "        # Randomly choose species\n",
        "        if random.random() < 0.5:\n",
        "            # Human account\n",
        "            account['species'] = 'Human'\n",
        "            # Assign human roles\n",
        "            account['role'] = random.choice(human_roles)\n",
        "            # Assign human-specific attributes\n",
        "            account['advocate_for_animals'] = random.choice(advocate_options)\n",
        "            account['current_lifestyle_diet'] = random.choice(lifestyle_options)\n",
        "            account['age'] = random.randint(5, 90)\n",
        "            account['gender'] = random.choice(genders)\n",
        "            account['ethnicity'] = random.choice(ethnicities)\n",
        "            account['country'] = random.choice(countries)\n",
        "            account['education_level'] = random.choice(education_levels)\n",
        "            account['income_level'] = random.choice(income_levels)\n",
        "            account['political_affiliation'] = random.choice(political_affiliations)\n",
        "            account['religious_affiliation'] = random.choice(religious_affiliations)\n",
        "\n",
        "            # Approach to animal advocacy (Scales from 0 to 1)\n",
        "            account['incrementalist_vs_abolitionist'] = round(random.uniform(0,1),2)\n",
        "            account['individual_vs_institutional'] = round(random.uniform(0,1),2)\n",
        "            account['solely_on_animal_activism_vs_intersectional'] = round(random.uniform(0,1),2)\n",
        "            account['focus_on_welfare_vs_rights'] = round(random.uniform(0,1),2)\n",
        "            account['diplomatic_vs_confrontational'] = round(random.uniform(0,1),2)\n",
        "            account['intuitive_vs_empirical_effectiveness'] = round(random.uniform(0,1),2)\n",
        "\n",
        "            # Psychometrics (Scales from 0 to 1)\n",
        "            account['openness_to_experience'] = round(random.uniform(0, 1), 2)\n",
        "            account['conscientiousness'] = round(random.uniform(0, 1), 2)\n",
        "            account['extraversion'] = round(random.uniform(0, 1), 2)\n",
        "            account['agreeableness'] = round(random.uniform(0, 1), 2)\n",
        "            account['neuroticism'] = round(random.uniform(0, 1), 2)\n",
        "\n",
        "            # Adversarial approach metrics (Scales from 0 to 1)\n",
        "            account['values_vs_profit'] = round(random.uniform(0, 1), 2)\n",
        "            account['short_term_vs_long_term'] = round(random.uniform(0, 1), 2)\n",
        "            account['innovation_vs_tradition'] = round(random.uniform(0, 1), 2)\n",
        "            account['pro_regulation_vs_anti_regulation'] = round(random.uniform(0, 1), 2)\n",
        "            account['transparency_vs_misinformation'] = round(random.uniform(0, 1), 2)\n",
        "            account['passive_vs_active'] = round(random.uniform(0, 1), 2)\n",
        "\n",
        "            print(f\"  Human Account Details: Role: {account['role']}, Current Lifestyle/Diet: {account['current_lifestyle_diet']}, Age: {account['age']}, Gender: {account['gender']}, Ethnicity: {account['ethnicity']}, Country: {account['country']}, Education Level: {account['education_level']}, Income Level: {account['income_level']}, Political Affiliation: {account['political_affiliation']}, Religious Affiliation: {account['religious_affiliation']}\")\n",
        "        else:\n",
        "            # Non-human account\n",
        "            account['species'] = random.choice(non_human_species)\n",
        "            account['role'] = random.choice(non_human_roles)\n",
        "            print(f\"  Non-Human Account Details: {account['species']} {account['role']}\")\n",
        "\n",
        "        accounts.append(account)\n",
        "        print(f\"Generated account {i+1}/{num_accounts}: {account['email']}\")\n",
        "\n",
        "    print(\"Finished generating synthetic accounts.\")\n",
        "    return accounts\n",
        "\n",
        "# Function to map scale values to descriptive terms\n",
        "def map_scale_to_term(value, low_term, high_term):\n",
        "    \"\"\"\n",
        "    Map a scale value (0 to 1) to descriptive terms.\n",
        "\n",
        "    Args:\n",
        "        value (float): The scale value.\n",
        "        low_term (str): Description for low values.\n",
        "        high_term (str): Description for high values.\n",
        "\n",
        "    Returns:\n",
        "        str: Descriptive term corresponding to the value.\n",
        "    \"\"\"\n",
        "    if value < 0.25:\n",
        "        return f'Highly {low_term}'\n",
        "    elif value < 0.5:\n",
        "        return f'Moderately {low_term}'\n",
        "    elif value < 0.75:\n",
        "        return f'Moderately {high_term}'\n",
        "    else:\n",
        "        return f'Highly {high_term}'\n",
        "\n",
        "def get_mime_type(url):\n",
        "    \"\"\"\n",
        "    Determine the MIME type based on the file extension.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the image file.\n",
        "\n",
        "    Returns:\n",
        "        str: The corresponding MIME type.\n",
        "    \"\"\"\n",
        "    extension = url.lower().split('.')[-1]\n",
        "    mime_types = {\n",
        "        'png': 'image/png',\n",
        "        'jpg': 'image/jpeg',\n",
        "        'jpeg': 'image/jpeg',\n",
        "        'gif': 'image/gif',\n",
        "        'webp': 'image/webp',\n",
        "        'tiff': 'image/tiff',\n",
        "        'tif': 'image/tiff',\n",
        "        'bmp': 'image/bmp',\n",
        "        'heic': 'image/heic',\n",
        "        'heif': 'image/heif',\n",
        "    }\n",
        "    return mime_types.get(extension, 'image/jpeg')  # Default to jpeg if unknown\n",
        "\n",
        "# Function to process input data and generate output\n",
        "def process_input_data(input_data, account):\n",
        "    \"\"\"\n",
        "    Process the input data to create an input task for the model.\n",
        "\n",
        "    Args:\n",
        "        input_data (dict): The input data from the JSON file.\n",
        "        account (dict): The synthetic account data.\n",
        "\n",
        "    Returns:\n",
        "        tuple(list, str)\n",
        "        list: The constructed input task.\n",
        "        str: The task type.\n",
        "    \"\"\"\n",
        "    print(f\"Processing input data: {input_data}\")\n",
        "    # Depending on the type of input_data, handle accordingly\n",
        "    if 'text' in input_data:\n",
        "        # Handle text data\n",
        "        return [\n",
        "            \"Please evaluate the following text: \",\n",
        "            input_data['text']\n",
        "        ], 'text'\n",
        "\n",
        "    if 'dialogue' in input_data:\n",
        "        # Handle dialogue data\n",
        "        dialogue_text = \"\\n\".join([f\"{item['author'].capitalize()}: {item['text']}\" for item in input_data['dialogue']])\n",
        "        print(\"Processed dialogue data.\")\n",
        "        return [\n",
        "            \"Please evaluate the following dialogue, focusing primarily on the last speaker's message \"\n",
        "            \"while considering the conversational context: \",\n",
        "            dialogue_text\n",
        "        ], 'chat'\n",
        "\n",
        "    if 'url' in input_data:\n",
        "        # Handle URL data (could be image or website)\n",
        "        url = input_data['url']\n",
        "        image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.webp', '.bmp', '.tiff', '.heic', '.heif')\n",
        "        if any(ext in url.lower() for ext in image_extensions):\n",
        "            # It's an image\n",
        "            print(f\"Processing image: {url}\")\n",
        "            return [\n",
        "                \"Please evaluate the following image: \",\n",
        "                Part.from_uri(url, mime_type=get_mime_type(url)),\n",
        "            ], 'image'\n",
        "        else:\n",
        "            # It's a website\n",
        "            print(f\"Processing website: {url}\")\n",
        "            website_content = scrape_website(url)\n",
        "            if website_content:\n",
        "                return [\n",
        "                    \"Please evaluate the content of this website: \",\n",
        "                    website_content\n",
        "                ], 'html_content'\n",
        "            else:\n",
        "                print(\"ERROR: Website content could not be retrieved.\")\n",
        "\n",
        "    # Unrecognized data format\n",
        "    print(f\"Error processing input data: {json.dumps(input_data)}\")\n",
        "    return [\n",
        "        \"Please evaluate the following data: \",\n",
        "        json.dumps(input_data)\n",
        "    ], 'text'\n",
        "\n",
        "# Function to scrape website content with truncation and relevance focus\n",
        "def scrape_website(url, max_chars=100000):\n",
        "    \"\"\"\n",
        "    Scrape text content from a website, focusing on the main content and truncating to a character limit.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the website.\n",
        "        max_chars (int): Maximum number of characters to return.\n",
        "\n",
        "    Returns:\n",
        "        str: The scraped and truncated text content.\n",
        "    \"\"\"\n",
        "    print(f\"Attempting to scrape website at URL: {url}\")\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            print(\"Website content retrieved successfully.\")\n",
        "            soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "            # Remove script, style, and irrelevant elements\n",
        "            for script in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\", \"aside\"]):\n",
        "                script.decompose()\n",
        "\n",
        "            # Extract text from relevant content tags\n",
        "            content = []\n",
        "            for tag in soup.find_all(['h1', 'h2', 'h3', 'p', 'li', 'blockquote']):\n",
        "                text = tag.get_text(separator=' ', strip=True)\n",
        "                if text:\n",
        "                    content.append(text)\n",
        "\n",
        "            # Combine the extracted text and truncate it\n",
        "            combined_content = ' '.join(content)\n",
        "            truncated_content = combined_content[:max_chars]\n",
        "\n",
        "            print(f\"Truncated website content to {len(truncated_content)} characters.\")\n",
        "            return truncated_content\n",
        "        else:\n",
        "            print(f\"Failed to retrieve website content. Status code: {response.status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Exception occurred while scraping website: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to use Vertex AI for generating output\n",
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "def generate_output_ranking(input_task, account):\n",
        "    \"\"\"\n",
        "    Use Vertex AI to generate an output based on the input task and account.\n",
        "\n",
        "    Args:\n",
        "        input_task (list): The input task for the model.\n",
        "        account (dict): The synthetic account data.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated JSON response from the model.\n",
        "    \"\"\"\n",
        "    print(\"Generating output ranking using the Vertex AI model...\")\n",
        "    try:\n",
        "        # Construct the approach description\n",
        "        persona = f\"Your synthetic persona details: {account}\"\n",
        "        prompt = [persona] + input_task\n",
        "\n",
        "        # Generate the response.\n",
        "        response = GENERATIVE_MODEL.generate_content(prompt)\n",
        "        print(\"Model response generated.\")\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while generating the output: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # Number of synthetic accounts to generate\n",
        "    num_accounts = 10000  # Adjust this number as needed to ensure manageability\n",
        "    print(f\"Starting main script. Dryrun={DRYRUN}\")\n",
        "    # Generate synthetic accounts\n",
        "    accounts = generate_synthetic_accounts(num_accounts)\n",
        "    account_index = 0  # Start from the first account\n",
        "\n",
        "    while True:\n",
        "        print(\"Checking for JSON files in the input bucket...\")\n",
        "        # List all JSON files in the input bucket\n",
        "        if DRYRUN:\n",
        "          blobs = list(input_bucket.list_blobs(prefix='web-page-feedback-English/', max_results=100))\n",
        "        else:\n",
        "          blobs = list(input_bucket.list_blobs())\n",
        "        json_blobs = [blob for blob in blobs if blob.name.endswith('.json')]\n",
        "        if not json_blobs:\n",
        "            print(\"No JSON files found in the input bucket. Waiting for new files...\")\n",
        "            time.sleep(60)  # Wait for 1 minute before checking again\n",
        "            continue\n",
        "\n",
        "        # Randomize the order of the JSON blobs\n",
        "        random.shuffle(json_blobs)\n",
        "        print(\"Randomized the order of input files.\")\n",
        "\n",
        "        for blob in json_blobs:\n",
        "            try:\n",
        "                print(f\"Processing file: {blob.name}\")\n",
        "                # Download the JSON file\n",
        "                data = blob.download_as_bytes()\n",
        "                input_data = json.loads(data)\n",
        "                print(\"Input data loaded.\")\n",
        "\n",
        "                # Get the current account\n",
        "                account = accounts[(account_index // 5) % len(accounts)]\n",
        "                account_index += 1\n",
        "                print(f\"Using account {account_index}: {account['email']}\")\n",
        "\n",
        "                selected_language = random.choice(SUPPORTED_LANGUAGES)\n",
        "                print(f\"Selected language for explanation field is: {selected_language}\")\n",
        "                formatted_instruction = SYSTEM_INSTRUCTION.replace(\n",
        "                    '# RESPONSE FORMATTING',\n",
        "                    f'''# RESPONSE FORMATTING\\n\n",
        "        Important: In your JSON response, you MUST write the \"explanation\" field in {selected_language}.\n",
        "        The rest of the response should be in English. Only this specific field should be written in {selected_language}.\\n'''\n",
        "                )\n",
        "\n",
        "                # Process the input data to create an input task\n",
        "                base_task, task_type = process_input_data(input_data, account)\n",
        "\n",
        "                # Combine the instruction with the base task\n",
        "                input_task = [formatted_instruction] + base_task\n",
        "\n",
        "                # Generate output ranking\n",
        "                response_text = generate_output_ranking(input_task, account)\n",
        "                if response_text is None:\n",
        "                    print(f\"Failed to generate response for {blob.name}\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"Generated response: {response_text}\")\n",
        "\n",
        "                # Parse the response text as JSON\n",
        "                try:\n",
        "                    response_json = json.loads(response_text)\n",
        "                    print(\"Model response parsed as JSON.\")\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Failed to parse response as JSON for {blob.name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                # Prepare the output data matching the sample output structure\n",
        "                result = []\n",
        "                schema_to_label = {\n",
        "                    \"is_content_harmful_to_animals\": {\n",
        "                        \"from_name\": \"is_content_harmful_to_animals\",\n",
        "                        \"type\": \"choices\",\n",
        "                        \"value\": {\"choices\": [response_json.get(\"is_content_harmful_to_animals\", \"No\")]}\n",
        "                    },\n",
        "                    \"explanation\": {\n",
        "                        \"from_name\": \"explanation\",\n",
        "                        \"type\": \"textarea\",\n",
        "                        \"value\": {\"text\": [response_json.get(\"explanation\", \"\")]}\n",
        "                    },\n",
        "                    \"rating_effect_on_animals\": {\n",
        "                        \"from_name\": \"rating_effect_on_animals\",\n",
        "                        \"type\": \"rating\",\n",
        "                        \"value\": {\"rating\": response_json.get(\"rating_effect_on_animals\", 3)}\n",
        "                    },\n",
        "                    \"rating_cultural_sensitivity\": {\n",
        "                        \"from_name\": \"rating_cultural_sensitivity\",\n",
        "                        \"type\": \"rating\",\n",
        "                        \"value\": {\"rating\": response_json.get(\"rating_cultural_sensitivity\", 3)}\n",
        "                    },\n",
        "                    \"rating_relevance\": {\n",
        "                        \"from_name\": \"rating_relevance\",\n",
        "                        \"type\": \"rating\",\n",
        "                        \"value\": {\"rating\": response_json.get(\"rating_relevance\", 3)}\n",
        "                    },\n",
        "                    \"rating_insight\": {\n",
        "                        \"from_name\": \"rating_insight\",\n",
        "                        \"type\": \"rating\",\n",
        "                        \"value\": {\"rating\": response_json.get(\"rating_insight\", 3)}\n",
        "                    },\n",
        "                    \"rating_trustworthiness\": {\n",
        "                        \"from_name\": \"rating_trustworthiness\",\n",
        "                        \"type\": \"rating\",\n",
        "                        \"value\": {\"rating\": response_json.get(\"rating_trustworthiness\", 3)}\n",
        "                    },\n",
        "                    \"rating_emotional_impact\": {\n",
        "                        \"from_name\": \"rating_emotional_impact\",\n",
        "                        \"type\": \"rating\",\n",
        "                        \"value\": {\"rating\": response_json.get(\"rating_emotional_impact\", 3)}\n",
        "                    },\n",
        "                    \"rating_rationality\": {\n",
        "                        \"from_name\": \"rating_rationality\",\n",
        "                        \"type\": \"rating\",\n",
        "                        \"value\": {\"rating\": response_json.get(\"rating_rationality\", 3)}\n",
        "                    },\n",
        "                    \"rating_influence\": {\n",
        "                        \"from_name\": \"rating_influence\",\n",
        "                        \"type\": \"rating\",\n",
        "                        \"value\": {\"rating\": response_json.get(\"rating_influence\", 3)}\n",
        "                    },\n",
        "                    \"rating_alignment\": {\n",
        "                        \"from_name\": \"rating_alignment\",\n",
        "                        \"type\": \"rating\",\n",
        "                        \"value\": {\"rating\": response_json.get(\"rating_alignment\", 3)}\n",
        "                    },\n",
        "                }\n",
        "\n",
        "                for key, mapping in schema_to_label.items():\n",
        "                    result.append({\n",
        "                        \"id\": str(uuid.uuid4()),\n",
        "                        \"from_name\": mapping[\"from_name\"],\n",
        "                        \"to_name\": task_type,\n",
        "                        \"type\": mapping[\"type\"],\n",
        "                        \"value\": mapping[\"value\"],\n",
        "                        \"origin\": \"manual\"\n",
        "                    })\n",
        "                print(\"Result data prepared.\")\n",
        "\n",
        "\n",
        "                # Prepare the output data\n",
        "                current_time = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%f\") + \"Z\"\n",
        "                task = {\n",
        "                    \"cancelled_annotations\": 0,\n",
        "                    \"comment_authors\": [],\n",
        "                    \"comment_count\": 0,\n",
        "                    \"created_at\": current_time,\n",
        "                    \"data\": input_data,\n",
        "                    \"file_upload\": None,\n",
        "                    \"id\": random.randint(100000, 999999),\n",
        "                    \"inner_id\": random.randint(100000, 999999),\n",
        "                    \"is_labeled\": True,\n",
        "                    \"last_comment_updated_at\": None,\n",
        "                    \"meta\": {},\n",
        "                    \"overlap\": 1,\n",
        "                    \"project\": 2480,\n",
        "                    \"total_annotations\": 1,\n",
        "                    \"total_predictions\": 0,\n",
        "                    \"unresolved_comment_count\": 0,\n",
        "                    \"updated_at\": current_time,\n",
        "                    \"updated_by\": None\n",
        "                }\n",
        "\n",
        "                output_data = {\n",
        "                    \"id\": random.randint(10000, 1000000),\n",
        "                    \"created_username\": account['email'],\n",
        "                    \"created_ago\": \"0 minutes\",\n",
        "                    \"completed_by\": {\n",
        "                        \"id\": account['id'],\n",
        "                        \"first_name\": account['first_name'],\n",
        "                        \"last_name\": account['last_name'],\n",
        "                        \"email\": account['email'],\n",
        "                        \"advocacy_diplomacy\": account['diplomatic_vs_confrontational'] if account['species'] == 'Human' else None,\n",
        "                        \"advocacy_empiricism\": account['intuitive_vs_empirical_effectiveness'] if account['species'] == 'Human' else None,\n",
        "                        \"advocacy_focus\": account['focus_on_welfare_vs_rights'] if account['species'] == 'Human' else None,\n",
        "                        \"advocacy_intersectionality\": account['solely_on_animal_activism_vs_intersectional'] if account['species'] == 'Human' else None,\n",
        "                        \"advocacy_rights\": account['focus_on_welfare_vs_rights'] if account['species'] == 'Human' else None,\n",
        "                        \"values_vs_profit\": account['values_vs_profit'] if account['species'] == 'Human' else None,\n",
        "                        \"short_term_vs_long_term\": account['short_term_vs_long_term'] if account['species'] == 'Human' else None,\n",
        "                        \"innovation_vs_tradition\": account['innovation_vs_tradition'] if account['species'] == 'Human' else None,\n",
        "                        \"pro_regulation_vs_anti_regulation\": account['pro_regulation_vs_anti_regulation'] if account['species'] == 'Human' else None,\n",
        "                        \"transparency_vs_misinformation\": account['transparency_vs_misinformation'] if account['species'] == 'Human' else None,\n",
        "                        \"passive_vs_active\": account['passive_vs_active'] if account['species'] == 'Human' else None,\n",
        "                        \"advocate\": account['advocate_for_animals'] if account['species'] == 'Human' else None,\n",
        "                        \"current_lifestyle\": account['current_lifestyle_diet'] if account['species'] == 'Human' else None,\n",
        "                        \"roles\": account['role'], # This field is common for both humans and non-humans\n",
        "                        \"age\": account['age'] if account['species'] == 'Human' else None,\n",
        "                        \"agreeableness\": account['agreeableness'] if account['species'] == 'Human' else None,\n",
        "                        \"conscientiousness\": account['conscientiousness'] if account['species'] == 'Human' else None,\n",
        "                        \"country\": account['country'] if account['species'] == 'Human' else None,\n",
        "                        \"education_level\": account['education_level'] if account['species'] == 'Human' else None,\n",
        "                        \"ethnicity\": account['ethnicity'] if account['species'] == 'Human' else None,\n",
        "                        \"extraversion\": account['extraversion'] if account['species'] == 'Human' else None,\n",
        "                        \"gender\": account['gender'] if account['species'] == 'Human' else None,\n",
        "                        \"income_level\": account['income_level'] if account['species'] == 'Human' else None,\n",
        "                        \"neuroticism\": account['neuroticism'] if account['species'] == 'Human' else None,\n",
        "                        \"openness\": account['openness_to_experience'] if account['species'] == 'Human' else None,\n",
        "                        \"political_affiliation\": account['political_affiliation'] if account['species'] == 'Human' else None,\n",
        "                        \"religious_affiliation\": account['religious_affiliation'] if account['species'] == 'Human' else None,\n",
        "                        \"species\": account['species']\n",
        "                    },\n",
        "                    \"draft_created_at\": current_time,\n",
        "                    \"task\": task,\n",
        "                    \"project\": 2480,\n",
        "                    \"updated_by\": account['id'],\n",
        "                    \"result\": result,\n",
        "                    \"was_cancelled\": False,\n",
        "                    \"ground_truth\": False,\n",
        "                    \"created_at\": current_time,\n",
        "                    \"updated_at\": current_time,\n",
        "                    \"lead_time\": random.uniform(1, 100),\n",
        "                    \"import_id\": None,\n",
        "                    \"last_action\": None,\n",
        "                    \"parent_prediction\": None,\n",
        "                    \"parent_annotation\": None,\n",
        "                    \"last_created_by\": None,\n",
        "                }\n",
        "                print(\"Output data assembled.\")\n",
        "\n",
        "                # Save the output data to the output bucket\n",
        "                output_name = OUTPUT_PREFIX + blob.name.replace('.json', '') + f\"-synthetic-{str(uuid.uuid4())}.json\"\n",
        "                if DRYRUN:\n",
        "                  print(f\"DRYRUN: Processed {output_name}\")\n",
        "                  print(json.dumps(output_data, indent=2))\n",
        "                else:\n",
        "                  output_blob = output_bucket.blob(output_name)\n",
        "                  output_blob.upload_from_string(json.dumps(output_data, indent=2), content_type='application/json')\n",
        "                  print(f\"Processed and saved output for {output_name}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while processing {blob.name}: {e}\")\n",
        "        # Sleep for a short while before checking for new files\n",
        "        print(\"Sleeping for 10 seconds before checking for new files...\")\n",
        "        time.sleep(10)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}